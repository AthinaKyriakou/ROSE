This file serves as a guide for the Rec-by-E model, users can refer to this file in order to understand the procedure of the model

# References
Rana, A. and Bridge, D.,
      2018, July. Explanations that are intrinsic to recommendations. In Proceedings of the
      26th Conference on User Modeling, Adaptation and Personalization (pp. 187-195).
 

# Overview of the model
The Rec-by-E recommender model as proposed in the below mentioned paper, aims at enhancing the recommendation process through so-called explanation chains. These should make it easier for the user to understand how recommendations have been created and help making the overall process more transparent.
Given a user, we generate explanation chains for all unknown items and subsequently rank them, finally we return the n items with the explanation chains generating the highest score as recommendations.
For the generation of explanation chains, we look at all items that are known to the user, and check if certain conditions are met:
1. The item has to have a certain similarity to the predecessor in the explanation chain
2. The item generates value to the explanation chain by adding to the overall reward. The reward hereby measures how much of the potentially recommended item can be explained by the potential predecessor, we do not consider features that have been expained by other items in the explanation chain already.

Once no further items fulfill all these requirements, we consider the explanation chain as complete.
The ranking process of all recommendation chains considers the overall reward per chain (sum of all rewards divided by the length of the chain), this can be interpreted as the average value added by each member, additionally the process considers how many new items a new chain adds to the recommendations. The more new items are contained in the explanation chain, the more diverse we consider this recommendation to be.

References: Rana, A. and Bridge, D.,
      2018, July. Explanations that are intrinsic to recommendations. In Proceedings of the
      26th Conference on User Modeling, Adaptation and Personalization (pp. 187-195).



# Files
* recom_rbye.py - entry point to the model, as this model is deterministic, we omit the fiting-function and only implement the scoring-function which computes the scores our model returns for a specific or all items given a specific user. (If further computational resources are available, the model could be enhanced by a fitting procedure to obtain the optimal parameters theta and epsilon, for now, these are static and can be set in the standard_params file)
* standard_params.py - here we define the standard parameters used in this model this ensures easy usability for experiments regarding these parameters

# Functions in detail
* fit - This function precomputes similarities between items so that the repeated computation is avoided

* generate_chains - we iterate over all items, if this item is known by the user, hence is existent in the users profile, we skip it, otherwise we go ahead and create explanation chains by appending explaining items to the chain until the previously mentioned conditions are no longer met by any item or if four items have been added to the chain. This consists of extracting the items that meet the conditions (valid_pred_candidates), next we find the item that creates the highest reward given the potentially recommended item together with its current explanation chain. For this item we add the reward generated by it to this explanation chains reward, append it to the chain and delete it from the candidate list to avoid double appearings.
Finally, if the chain is longer than 1, meaning the explanation chain has at least one additional item next to the potentially recommended item, we save it.
This function returns a list of explanation chains together with a list of their rewards.

* rank_chains - We order the explanation chains step by step by computing the score of the chains.

* get_similarity - This function computes the similarity between two items, using the Jaccard similarity measures and the items text data. In detail, we determine the number of shared features by multiplying the two keyword-lists, all values that are non-zero refer to shared features. On the other hand, if we sum up the two keyword-lists, all non-zero values refer to keywords that are present in at least one of the items text data. Finally, we divide the number of the shared features by the number of total features and return this score.

* get_reward - This function computes the reward that a potential predecessor adds to an existing explanation chain. For this purpose we extract the keywords used in the potential predecessor, the keywords used in the potentially recommended item and lastly the keywords used in all items that are already part of the explanation chain.
As we sum up the keyword-lists of the chain-members, we firstly have to subtract the keyword-list of the potentially recommended item, afterwards we set all non-zero values to 1 in order to be able to compare the features-lists to each other. Next, we extract a list representing the features in our target item that have not yet been covered by subtracting the chain-features from the candidate-features, all values that are below zero will be set to zero. Now we have obtained a list of all uncovered features of the target item.
Finally, we determine how many of those uncovered features can be covered by the potential predecessor and compute the reward by diving the number of newly covered features by the number of uncovered features and adding another factor (dividing the number of newly covered features by the number of features in the predecessor) that accounts for the number of keywords in the potential predecessor. This ensures balance between items with a small number of keywords and items with a large number of keywords.
Finally, this reward will be returned.

* get_score - This function computes how much value a new explanation chain adds to a users recommended items. For this purpose we consider all items that have been utilized in explanation chains that are already selected as recommendations. We determine how many items this potential new explanation chain contains that are NOT yet present in the previous explanation chains. Finally, the score is put together of this explanation chains reward divided by its length and the number of new items in this explanation chain divided by the the total number of items in the same.

* recommend  - This function takes a list of user and returns the n best recommendations for each. Unlike other models, this recommender already generates explanation while generating recommendations, hence we also include the explanation for each recommendation.