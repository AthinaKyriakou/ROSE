{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainer Experiment Demo\n",
    "\n",
    "Below we show some examples on how you can use the **Experiment_Explainers** class. The general steps consist of:\n",
    "1. prepare data\n",
    "2. Initialize recommenders, explainers and metrics\n",
    "3. Initialize experiment and run the experiment\n",
    "\n",
    "You can set distribution=True to enable distribution plots while running the experiments. The plots will be saved in /experiment_plots.\n",
    "\n",
    "When the experiment is completed, result table is saved in /experiment_plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 1**: run PSPNFNS, FDIV and FPR on (FM, Exp_LIMERS) pair using rating data and sentiment data from amazon toys. Since this dataset does not contain explicit item and user features, we parsed aspect and opinion from sentiment data as item and user features respectively in the  ***create_item_features_from_aspects*** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.datasets import amazon_toy\n",
    "import numpy as np\n",
    "from cornac.data import FeatureModality\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.experiment import Experiment_Explainers\n",
    "from cornac.models import FMRec\n",
    "from cornac.explainer import Exp_LIMERS\n",
    "from cornac.metrics_explainer import (\n",
    "    Metric_Exp_PSPNFNS as PSPN,\n",
    "    Metric_Exp_DIV as DIV,\n",
    "    Metric_Exp_FPR as FPR,\n",
    ")\n",
    "\n",
    "\n",
    "def create_item_features_from_aspects(at_sentiment):\n",
    "    \"\"\"Separate aspects and opinions from sentiment data and create item and user features from them.\"\"\"\n",
    "    items = {}\n",
    "    users = {}\n",
    "    for _, row in enumerate(at_sentiment):\n",
    "        user, item, sentiments = row\n",
    "        if user not in users:\n",
    "            users[user] = []\n",
    "        if item not in items:\n",
    "            items[item] = []\n",
    "        for sentiment in sentiments:\n",
    "            if sentiment[0] not in items[item]:\n",
    "                items[item].append(sentiment[0])  # aspect adds to item feature\n",
    "            if sentiment[1] not in users[user]:\n",
    "                users[user].append(sentiment[1])  # opinion adds to user feature\n",
    "\n",
    "    item_aspect_pairs = np.array(\n",
    "        [(item, feature) for item in items for feature in items[item]]\n",
    "    )\n",
    "    user_opinion_pairs = np.array(\n",
    "        [(user, feature) for user in users for feature in users[user]]\n",
    "    )\n",
    "    return item_aspect_pairs, user_opinion_pairs, items.keys(), users.keys()\n",
    "\n",
    "\n",
    "at_feedback = amazon_toy.load_feedback()\n",
    "at_feedback = at_feedback[: len(at_feedback) // 20]  # reduce data size\n",
    "at_sentiment = amazon_toy.load_sentiment()\n",
    "items_feature, users_feature, items_list, users_list = (\n",
    "    create_item_features_from_aspects(at_sentiment)\n",
    ")\n",
    "# remove unknown users and items from rating data\n",
    "at_feedback_excl_unknowns = [\n",
    "    x for x in at_feedback if x[0] in users_list and x[1] in items_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender FMRec...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.84335\n",
      "-- Epoch 2\n",
      "Training MSE: 0.54054\n",
      "-- Epoch 3\n",
      "Training MSE: 0.47963\n",
      "-- Epoch 4\n",
      "Training MSE: 0.43793\n",
      "-- Epoch 5\n",
      "Training MSE: 0.40798\n",
      "-- Epoch 6\n",
      "Training MSE: 0.38155\n",
      "-- Epoch 7\n",
      "Training MSE: 0.36740\n",
      "-- Epoch 8\n",
      "Training MSE: 0.35302\n",
      "-- Epoch 9\n",
      "Training MSE: 0.34088\n",
      "-- Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'FMRec:Exp_LIMERS'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Recommender FMRec creates recommendations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.33139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer Exp_LIMERS create explanation for all recommendations\n",
      "Computing explanations: : 20537it [07:39, 44.66it/s]                         \n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_PSPNFNS starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:self.current_rec: FMRec, self.current_exp: Exp_LIMERS\n",
      "Re-evaluate after features removal... : 20537it [06:49, 50.21it/s]                           \n",
      "INFO:cornac.experiment.experiment_explainers:Result: Probability of Necessity: 0.9873071979434447; Probability of Sufficiency: 0.0; Harmonic Mean: 0.0\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_DIV starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Feature diversity: 0.08820979829202373\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_FPR starts evaluation...\n",
      "ERROR:cornac.experiment.experiment_explainers:Metric Metric_Exp_FPR does not support Exp_LIMERS.\n",
      "INFO:cornac.experiment.experiment_explainers:experiment data: [[0.0, 0.08820979829202373, 'N/A', 13.353046178817749, 1270.946202993393]]\n",
      "INFO:cornac.experiment.experiment_explainers:Experiment result: \n",
      " recommender:explainer | Metric_Exp_PSPNFNS |      Metric_Exp_DIV | Metric_Exp_FPR |           Train(s) |       Evaluate(s)\n",
      "FMRec:Exp_LIMERS      |                0.0 | 0.08820979829202373 |            N/A | 13.353046178817749 | 1270.946202993393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "rs = RatioSplit(\n",
    "    data=at_feedback,\n",
    "    test_size=0.2,\n",
    "    item_feature=FeatureModality(items_feature),\n",
    "    # user_feature=FeatureModality(users_feature), # user feature is not used in this experiment\n",
    "    seed=42,\n",
    "    exclude_unknowns=True,\n",
    ")\n",
    "# initialize recommenders, explainers and metrics\n",
    "fm = FMRec()\n",
    "limers = Exp_LIMERS(rec_model=fm, dataset=rs.train_set)\n",
    "pspnfns = PSPN()\n",
    "fdiv = DIV()\n",
    "fpr = FPR()\n",
    "\n",
    "# initialize experiment\n",
    "models = [(fm, limers)]\n",
    "metrics = [pspnfns, fdiv, fpr]\n",
    "experiment = Experiment_Explainers(\n",
    "    eval_method=rs,\n",
    "    models=models,\n",
    "    metrics=metrics,\n",
    "    distribution=True,\n",
    "    rec_k=4,\n",
    "    feature_k=4,\n",
    "    eval_train=True,\n",
    ")\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 2**: run PSPN, FDIV and FPR on (EFM, Exp_EFM), (MTER, Exp_MTER), (ComparERObj, Exp_ComparERObj) and (ComparERSub, Exp_ComparERSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaoyao/miniconda3/envs/rose/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/yaoyao/miniconda3/envs/rose/lib/python3.9/site-packages/flatbuffers/compat.py:19: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 119\n",
      "Number of items = 4058\n",
      "Number of ratings = 7197\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 4.3\n",
      "---\n",
      "Test data:\n",
      "Number of users = 119\n",
      "Number of items = 4058\n",
      "Number of ratings = 741\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Total users = 119\n",
      "Total items = 4058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender EFM...\n",
      "/Users/yaoyao/miniconda3/envs/rose/lib/python3.9/site-packages/cornac-2.0.0-py3.9-macosx-11.1-arm64.egg/cornac/models/recommender.py:307: UserWarning: Model is already fitted. Re-fitting will overwrite the previous model.\n",
      "  warnings.warn(\n",
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'EFM:Exp_EFM'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Recommender EFM creates recommendations\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer Exp_EFM create explanation for all recommendations\n",
      "Computing explanations: 100%|██████████| 1190/1190 [00:00<00:00, 5580.88it/s]\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_DIV starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Feature diversity: 0.6092330960971876\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_FPR starts evaluation...\n",
      "Start evaluation... : 7909it [00:01, 5747.63it/s]                           \n",
      "INFO:cornac.experiment.experiment_explainers:Result: Feature Precision: 0.6976217281170842; Feature Recall: 0.08985864640884805; Harmonic Mean: 0.15173801621456384\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_PSPNFNS starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:self.current_rec: EFM, self.current_exp: Exp_EFM\n",
      "Re-evaluate after features removal... : 100%|██████████| 1190/1190 [00:18<00:00, 62.78it/s]\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Probability of Necessity: 0.03361344537815126; Probability of Sufficiency: 0.5445378151260504; Harmonic Mean: 0.06331835059605237\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender EFM...\n",
      "/Users/yaoyao/miniconda3/envs/rose/lib/python3.9/site-packages/cornac-2.0.0-py3.9-macosx-11.1-arm64.egg/cornac/models/recommender.py:307: UserWarning: Model is already fitted. Re-fitting will overwrite the previous model.\n",
      "  warnings.warn(\n",
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'EFM:Exp_Counter'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Recommender EFM creates recommendations\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer Exp_Counter create explanation for all recommendations\n",
      "Computing explanations:   0%|          | 0/1190 [00:00<?, ?it/s]/Users/yaoyao/miniconda3/envs/rose/lib/python3.9/site-packages/scipy/sparse/_index.py:151: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "/Users/yaoyao/miniconda3/envs/rose/lib/python3.9/site-packages/cornac-2.0.0-py3.9-macosx-11.1-arm64.egg/cornac/models/recommender.py:307: UserWarning: Model is already fitted. Re-fitting will overwrite the previous model.\n",
      "  warnings.warn(\n",
      "Computing explanations:  39%|███▉      | 470/1190 [14:34<05:07,  2.34it/s]  "
     ]
    }
   ],
   "source": [
    "from cornac.experiment import Experiment_Explainers\n",
    "from cornac.models import MTER, EFM, ComparERObj, ComparERSub\n",
    "from cornac.explainer import Exp_EFM, Exp_MTER, Exp_ComparERObj, Exp_ComparERSub, Exp_Counter\n",
    "from cornac.metrics_explainer import (\n",
    "    Metric_Exp_PSPNFNS as PSPN,\n",
    "    Metric_Exp_DIV as DIV,\n",
    "    Metric_Exp_FPR as FPR,\n",
    ")\n",
    "from cornac.datasets import amazon_toy\n",
    "from cornac.data.reader import Reader\n",
    "from cornac.eval_methods import StratifiedSplit\n",
    "from cornac.data.sentiment import SentimentModality\n",
    "\n",
    "rating = amazon_toy.load_feedback(fmt=\"UIRT\", reader=Reader(min_user_freq=50))\n",
    "sentiment_data = amazon_toy.load_sentiment(reader=Reader(min_user_freq=50))\n",
    "\n",
    "md = SentimentModality(data=sentiment_data)\n",
    "\n",
    "eval_method = StratifiedSplit(\n",
    "    data=rating,\n",
    "    group_by=\"user\",\n",
    "    chrono=True,\n",
    "    sentiment=md,\n",
    "    test_size=0.2,\n",
    "    exclude_unknowns=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# initialize recommenders and explainers\n",
    "efm = EFM(\n",
    "    max_iter=20,\n",
    "    num_explicit_factors=128,\n",
    "    num_latent_factors=128,\n",
    "    num_most_cared_aspects=100,\n",
    "    rating_scale=5.0,\n",
    "    alpha=0.9,\n",
    "    lambda_x=1,\n",
    "    lambda_y=1,\n",
    "    lambda_u=0.01,\n",
    "    lambda_h=0.01,\n",
    "    lambda_v=0.01,\n",
    "    trainable=True,\n",
    ")\n",
    "efm_exp = Exp_EFM(rec_model=efm, dataset=eval_method.train_set)\n",
    "counter = Exp_Counter(rec_model=efm, dataset=eval_method.train_set, rec_k=10)\n",
    "mter = MTER(\n",
    "    max_iter=20,\n",
    "    n_user_factors=8,\n",
    "    n_item_factors=8,\n",
    "    n_aspect_factors=8,\n",
    "    n_opinion_factors=8,\n",
    "    n_bpr_samples=1000,\n",
    "    n_element_samples=50,\n",
    "    lambda_reg=0.1,\n",
    "    lambda_bpr=10,\n",
    "    lr=0.5,\n",
    ")\n",
    "mter_exp = Exp_MTER(rec_model=mter, dataset=eval_method.train_set)\n",
    "\n",
    "efm.fit(eval_method.train_set)\n",
    "params = {\n",
    "        \"U1\": efm.U1,\n",
    "        \"U2\": efm.U2,\n",
    "        \"H1\": efm.H1,\n",
    "        \"H2\": efm.H2,\n",
    "        \"V\": efm.V,\n",
    "}\n",
    "comparerobj = ComparERObj(\n",
    "    max_iter=20,\n",
    "    num_explicit_factors=128,\n",
    "    num_latent_factors=128,\n",
    "    num_most_cared_aspects=20,\n",
    "    rating_scale=5.0,\n",
    "    alpha=0.7,\n",
    "    lambda_x=1,\n",
    "    lambda_y=1,\n",
    "    lambda_u=0.01,\n",
    "    lambda_h=0.01,\n",
    "    lambda_v=0.01,\n",
    "    lambda_d=0.1,\n",
    "    min_user_freq=2,\n",
    "    trainable=True,\n",
    "    verbose=True,\n",
    "    init_params=params,\n",
    ")\n",
    "exp_comparerobj = Exp_ComparERObj(comparerobj, eval_method.train_set)\n",
    "\n",
    "mter.fit(eval_method.train_set)\n",
    "params = {\n",
    "    \"G1\": mter.G1,\n",
    "    \"G2\": mter.G2,\n",
    "    \"G3\": mter.G3,\n",
    "    \"U\": mter.U,\n",
    "    \"I\": mter.I,\n",
    "    \"A\": mter.A,\n",
    "    \"O\": mter.O,\n",
    "}\n",
    "\n",
    "comparersub = ComparERSub(\n",
    "    max_iter=20,\n",
    "    n_user_factors=8,\n",
    "    n_item_factors=8,\n",
    "    n_aspect_factors=8,\n",
    "    n_opinion_factors=8,\n",
    "    n_pair_samples=1000,\n",
    "    n_bpr_samples=1000,\n",
    "    n_element_samples=50,\n",
    "    lambda_reg=0.1,\n",
    "    lambda_bpr=10,\n",
    "    lambda_d=10,\n",
    "    lr=0.5,\n",
    "    min_common_freq=1,\n",
    "    min_user_freq=2,\n",
    "    min_pair_freq=1,\n",
    "    trainable=True,\n",
    "    verbose=True,\n",
    "    init_params=params,\n",
    ")\n",
    "exp_comparersub = Exp_ComparERSub(comparersub, eval_method.train_set)\n",
    "\n",
    "\n",
    "# initialize metrics\n",
    "pspnfns = PSPN()\n",
    "fdiv = DIV()\n",
    "fpr = FPR()\n",
    "fpr_with_input_as_groundtruth = FPR(ground_truth=sentiment_data)\n",
    "\n",
    "# initialize experiment\n",
    "models = [(efm, efm_exp), (efm, counter), (mter, mter_exp), (comparerobj, exp_comparerobj), (comparersub, exp_comparersub)]\n",
    "metrics = [fdiv, fpr_with_input_as_groundtruth, pspnfns]\n",
    "experiment = Experiment_Explainers(\n",
    "    eval_method=eval_method,\n",
    "    models=models,\n",
    "    metrics=metrics,\n",
    "    rec_k=10,\n",
    "    distribution=False,\n",
    "    feature_k=10,\n",
    "    eval_train=True,\n",
    ")\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 3**: run FDIV, PGF, MEP and EnDCG on (ALS, Exp_ALS), (EMF, Exp_PHI4MF) and (NEMF, Exp_SU4EMF) pairs using data from movielens. This dataset only contains user, item and rating info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linan/miniconda3/envs/cornac/lib/python3.11/site-packages/tensorflow/python/debug/cli/debugger_cli_common.py:19: DeprecationWarning: module 'sre_constants' is deprecated\n",
      "  import sre_constants\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender EMF...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 1.0\n",
      "exclude_unknowns = False\n",
      "---\n",
      "Training data:\n",
      "Number of users = 230\n",
      "Number of items = 1619\n",
      "Number of ratings = 46456\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 230\n",
      "Number of items = 1653\n",
      "Number of ratings = 11615\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 34\n",
      "---\n",
      "Total users = 230\n",
      "Total items = 1653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd414f981ad48f1a60b7e13cba1f5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'EMF:Exp_PHI4MF'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Recommender EMF creates recommendations\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer Exp_PHI4MF create explanation for all recommendations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a9d4a637a64a269eebd1d1a0b184cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association rules generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_DIV starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Feature diversity: 0.003886325252432064\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_PGF starts evaluation...\n",
      "100%|██████████| 230/230 [00:03<00:00, 69.91it/s]\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Metric_Exp_PGF: 0.08064328547486145\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_MEP starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Metric_Exp_MEP: 0.6843478260869565\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_EnDCG starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Metric_Exp_EnDCG: 0.3148327388807963\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender ALS...\n",
      "/home/linan/miniconda3/envs/cornac/lib/python3.11/site-packages/implicit/cpu/als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 6 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9596f8b8a9ce44c696e470dbb5d6690d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:implicit:Final training loss 0.1006\n",
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'ALS:Exp_ALS'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Recommender ALS creates recommendations\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer Exp_ALS create explanation for all recommendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f17f20722048288c2191bee0156743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_DIV starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Feature diversity: 0.0361189553114514\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_PGF starts evaluation...\n",
      "100%|██████████| 230/230 [00:02<00:00, 112.29it/s]\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Metric_Exp_PGF: 0.23168851814495722\n",
      "ERROR:cornac.experiment.experiment_explainers:Metric Metric_Exp_MEP does not support Exp_ALS.\n",
      "ERROR:cornac.experiment.experiment_explainers:Metric Metric_Exp_EnDCG does not support Exp_ALS.\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender NEMF...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start compute edge weight matrix...\n",
      "Start compute novel matrix...\n",
      "Matrix computation finished!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8677af6d914d49a9f20e74d30e63f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'NEMF:Exp_SU4EMF'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Recommender NEMF creates recommendations\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer Exp_SU4EMF create explanation for all recommendations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f053aca8bb7b4a09b60617142727b7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/2300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_DIV starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Feature diversity: 0.2297882783392449\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_PGF starts evaluation...\n",
      "100%|██████████| 230/230 [00:00<00:00, 319.37it/s]\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Metric_Exp_PGF: 0.02494628222598492\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_MEP starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Metric_Exp_MEP: 0.29130434782608694\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_EnDCG starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Metric_Exp_EnDCG: 0.12516964557088964\n",
      "INFO:cornac.experiment.experiment_explainers:experiment data: [[0.003886325252432064, 0.08064328547486145, 0.6843478260869565, 0.3148327388807963, 2.9156980514526367, 231.64698433876038], [0.0361189553114514, 0.23168851814495722, 'N/A', 'N/A', 10.128460168838501, 28.07982611656189], [0.2297882783392449, 0.02494628222598492, 0.29130434782608694, 0.12516964557088964, 3.973614454269409, 5.55441951751709]]\n",
      "INFO:cornac.experiment.experiment_explainers:Experiment result: \n",
      " recommender:explainer |       Metric_Exp_DIV |      Metric_Exp_PGF |      Metric_Exp_MEP |    Metric_Exp_EnDCG |           Train(s) |        Evaluate(s)\n",
      "EMF:Exp_PHI4MF        | 0.003886325252432064 | 0.08064328547486145 |  0.6843478260869565 |  0.3148327388807963 | 2.9156980514526367 | 231.64698433876038\n",
      "ALS:Exp_ALS           |   0.0361189553114514 | 0.23168851814495722 |                 N/A |                 N/A | 10.128460168838501 |  28.07982611656189\n",
      "NEMF:Exp_SU4EMF       |   0.2297882783392449 | 0.02494628222598492 | 0.29130434782608694 | 0.12516964557088964 |  3.973614454269409 |   5.55441951751709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cornac.datasets import movielens\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.data.reader import Reader\n",
    "from cornac.experiment.experiment_explainers import Experiment_Explainers\n",
    "from cornac.models import EMF, NEMF, ALS\n",
    "from cornac.explainer import Exp_ALS, Exp_PHI4MF, Exp_SU4EMF\n",
    "from cornac.metrics_explainer import (\n",
    "    Metric_Exp_DIV as DIV,\n",
    "    Metric_Exp_PGF as PGF,\n",
    "    Metric_Exp_MEP as MEP,\n",
    "    Metric_Exp_EnDCG as EnDCG,\n",
    ")\n",
    "\n",
    "# Load MovieLens\n",
    "data = movielens.load_feedback(variant=\"100K\", reader=Reader(min_user_freq=150))\n",
    "\n",
    "# Define an evaluation method to split feedback into train and test sets\n",
    "ratio_split = RatioSplit(\n",
    "    data=data, test_size=0.2, exclude_unknowns=False, verbose=True\n",
    ")\n",
    "\n",
    "# initialize recommenders and explainers\n",
    "emf = EMF(\n",
    "    k=10,\n",
    "    max_iter=500,\n",
    "    learning_rate=0.001,\n",
    "    lambda_reg=0.1,\n",
    "    explain_reg=0.01,\n",
    "    verbose=True,\n",
    "    seed=6,\n",
    "    num_threads=6,\n",
    "    early_stop=True,\n",
    ")\n",
    "nemf = NEMF(\n",
    "    k=10,\n",
    "    max_iter=500,\n",
    "    learning_rate=0.001,\n",
    "    lambda_reg=0.1,\n",
    "    explain_reg=0.01,\n",
    "    novel_reg=1,\n",
    "    verbose=True,\n",
    "    seed=6,\n",
    "    num_threads=6,\n",
    "    early_stop=True,\n",
    ")\n",
    "als = ALS(k=10, max_iter=500, lambda_reg=0.001, alpha=1, verbose=True, seed=6)\n",
    "als_exp = Exp_ALS(rec_model=als, dataset=ratio_split.train_set)\n",
    "emf_exp = Exp_PHI4MF(rec_model=emf, dataset=ratio_split.train_set)\n",
    "nemf_exp = Exp_SU4EMF(rec_model=nemf, dataset=ratio_split.train_set)\n",
    "\n",
    "# initialize metrics\n",
    "fdiv = DIV()\n",
    "pgf = PGF()\n",
    "mep = MEP()\n",
    "endcg = EnDCG()\n",
    "\n",
    "# initialize experiment\n",
    "models = [(emf, emf_exp), (als, als_exp), (nemf, nemf_exp)]\n",
    "metrics = [fdiv, pgf, mep, endcg]\n",
    "experiment = Experiment_Explainers(\n",
    "    eval_method=ratio_split,\n",
    "    models=models,\n",
    "    metrics=metrics,\n",
    "    distribution=False,\n",
    "    rec_k=10,\n",
    "    feature_k=10,\n",
    "    eval_train=True,\n",
    ")\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 4**: Run RA and FA on pairwise models. FA and RA performs comparison between two sets of explainers, thus the score is unavailable when only one explainer is passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 119\n",
      "Number of items = 4058\n",
      "Number of ratings = 7197\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 4.3\n",
      "---\n",
      "Test data:\n",
      "Number of users = 119\n",
      "Number of items = 4058\n",
      "Number of ratings = 741\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Total users = 119\n",
      "Total items = 4058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender1 EFM...\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender2 MTER...\n",
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'EFM:Exp_EFM'vs'MTER:Exp_MTER'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Creates fake recommendations from dataset for common used\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer1 Exp_EFM create explanation for all recommendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58516c4830b04eceb93de4a637ad3b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer2 Exp_MTER create explanation for all recommendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd1506e48284244ad01ee3b56244ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_FA starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Average Metric_Exp_FA: 0.1176470588235293\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_RA starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Average Metric_Exp_RA: 0.06576630652260904\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender1 EFM...\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender2 ComparERObj...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building rating matrix completed in 0 s\n",
      "Building user aspect attention matrix completed in 0 s\n",
      "Building item aspect quality matrix completed in 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get purchased pairs: 100%|██████████| 119/119 [00:00<00:00, 454.42it/s]\n",
      "Get skyline aspects: 100%|██████████| 297317/297317 [01:55<00:00, 2580.07it/s]\n",
      "Enumerate index: 100%|██████████| 2010482/2010482 [00:00<00:00, 3214111.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building chrono purchared items pairs completed in 116 s\n",
      "Statistics: # aspect pairs >= 1 = 1425157, min(1.00), max(9.00), avg(1.10)\n",
      "# earlier-later pairs: 306188, # unique earlier-later pairs: 297317, not dominated pairs 278467, # comparable pairs 1425157\n",
      "Building matrices completed!\n",
      "iter: 1, loss: 5948.74, aspect bpr loss: 98423.52, correct: 934382\n",
      "iter: 2, loss: 28893.52, aspect bpr loss: 51220.32, correct: 1239443\n",
      "iter: 3, loss: 23027.28, aspect bpr loss: 48979.77, correct: 1277276\n",
      "iter: 4, loss: 25401.06, aspect bpr loss: 45650.14, correct: 1288086\n",
      "iter: 5, loss: 24162.38, aspect bpr loss: 44649.79, correct: 1299656\n",
      "iter: 6, loss: 24579.55, aspect bpr loss: 43081.93, correct: 1306535\n",
      "iter: 7, loss: 23793.81, aspect bpr loss: 42256.21, correct: 1313748\n",
      "iter: 8, loss: 23784.72, aspect bpr loss: 41137.29, correct: 1319224\n",
      "iter: 9, loss: 23143.59, aspect bpr loss: 40399.05, correct: 1324895\n",
      "iter: 10, loss: 22978.63, aspect bpr loss: 39474.91, correct: 1329732\n",
      "iter: 11, loss: 22407.87, aspect bpr loss: 38793.14, correct: 1334509\n",
      "iter: 12, loss: 22176.08, aspect bpr loss: 37976.99, correct: 1338672\n",
      "iter: 13, loss: 21655.71, aspect bpr loss: 37333.83, correct: 1342850\n",
      "iter: 14, loss: 21396.65, aspect bpr loss: 36587.65, correct: 1346512\n",
      "iter: 15, loss: 20920.21, aspect bpr loss: 35975.08, correct: 1350172\n",
      "iter: 16, loss: 20653.44, aspect bpr loss: 35281.06, correct: 1353420\n",
      "iter: 17, loss: 20217.36, aspect bpr loss: 34694.23, correct: 1356635\n",
      "iter: 18, loss: 19951.94, aspect bpr loss: 34044.38, correct: 1359691\n",
      "iter: 19, loss: 19552.79, aspect bpr loss: 33482.03, correct: 1362674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'EFM:Exp_EFM'vs'ComparERObj:Exp_ComparERObj'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Creates fake recommendations from dataset for common used\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer1 Exp_EFM create explanation for all recommendations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 20, loss: 19293.43, aspect bpr loss: 32869.68, correct: 1365413\n",
      "Optimization finished!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce512c271a9b4efa998a67202d10c9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer2 Exp_ComparERObj create explanation for all recommendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41886efda804415b94b96b5f84ed995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_FA starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Average Metric_Exp_FA: 1.0\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_RA starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Average Metric_Exp_RA: 1.0\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender1 MTER...\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender2 ComparERSub...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building data started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count aspects: 100%|██████████| 114/114 [00:00<00:00, 562.57it/s]\n",
      "Compute X: 100%|██████████| 33698/33698 [00:00<00:00, 736673.53it/s]\n",
      "Compute YU: 100%|██████████| 18989/18989 [00:00<00:00, 383182.53it/s]\n",
      "Compute YI: 100%|██████████| 23772/23772 [00:00<00:00, 533766.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building item aspect quality matrix completed in 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get purchased pairs: 100%|██████████| 119/119 [00:00<00:00, 518.11it/s]\n",
      "Get skyline aspects: 100%|██████████| 306188/306188 [35:11<00:00, 145.02it/s]\n",
      "Enumerate index: 100%|██████████| 888109/888109 [00:00<00:00, 2831964.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building chrono purchared items pairs completed in 2112 s\n",
      "Statistics: # aspect pairs >= 1 = 559835, min(1.00), max(1.00), avg(1.00)\n",
      "# earlier-later pairs: 306188, # unique earlier-later pairs: 306188, not dominated pairs 279800, # comparable pairs 559835\n",
      "Building data completed in 2112 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 46.96it/s, loss=9.34, bpr_loss=-0.60, correct=56.41%, skipped=0.20%] \n",
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'MTER:Exp_MTER'vs'ComparERSub:Exp_ComparERSub'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Creates fake recommendations from dataset for common used\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer1 Exp_MTER create explanation for all recommendations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87eabb8f45274e93a02f7102dfccc01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer2 Exp_ComparERSub create explanation for all recommendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fa0cfdb7784143b8436f90b9292be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_FA starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Average Metric_Exp_FA: 0.9943977591036414\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_RA starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Average Metric_Exp_RA: 0.992530345471522\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender1 EFM...\n",
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender2 TriRank...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building matrices started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1930094ffa704c57b7d014c99d243541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building matrices:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building symmetric normalized matrices R, X, Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'EFM:Exp_EFM'vs'TriRank:Exp_TriRank'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Creates fake recommendations from dataset for common used\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer1 Exp_EFM create explanation for all recommendations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building matrices completed in 0 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd994fa8f0034a379c26c45889444bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer2 Exp_TriRank create explanation for all recommendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9def12e9770549a082b30366bdf32c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_FA starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Average Metric_Exp_FA: 0.1478991596638654\n",
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_RA starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Average Metric_Exp_RA: 0.007563025210084033\n",
      "INFO:cornac.experiment.experiment_explainers:experiment data: [[0.1176470588235293, 0.06576630652260904, 0.9829080104827881, 0.4178743362426758], [1.0, 1.0, 128.8874969482422, 0.10132598876953125], [0.9943977591036414, 0.992530345471522, 2113.6905925273895, 0.611400842666626], [0.1478991596638654, 0.007563025210084033, 1.3195741176605225, 0.22526264190673828]]\n",
      "INFO:cornac.experiment.experiment_explainers:Experiment result: \n",
      " recommender:explainer                        |      Metric_Exp_FA |        Metric_Exp_RA |           Train(s) |         Evaluate(s)\n",
      "EFM:Exp_EFM'vs'MTER:Exp_MTER                 | 0.1176470588235293 |  0.06576630652260904 | 0.9829080104827881 |  0.4178743362426758\n",
      "EFM:Exp_EFM'vs'ComparERObj:Exp_ComparERObj   |                1.0 |                  1.0 |  128.8874969482422 | 0.10132598876953125\n",
      "MTER:Exp_MTER'vs'ComparERSub:Exp_ComparERSub | 0.9943977591036414 |    0.992530345471522 | 2113.6905925273895 |   0.611400842666626\n",
      "EFM:Exp_EFM'vs'TriRank:Exp_TriRank           | 0.1478991596638654 | 0.007563025210084033 | 1.3195741176605225 | 0.22526264190673828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cornac.experiment import Experiment_Explainers\n",
    "from cornac.models import MTER, EFM, ComparERObj, ComparERSub, TriRank\n",
    "from cornac.explainer import (\n",
    "    Exp_EFM,\n",
    "    Exp_MTER,\n",
    "    Exp_ComparERObj,\n",
    "    Exp_ComparERSub,\n",
    "    Exp_TriRank,\n",
    ")\n",
    "from cornac.datasets import amazon_toy\n",
    "from cornac.data.reader import Reader\n",
    "from cornac.eval_methods import StratifiedSplit\n",
    "from cornac.data.sentiment import SentimentModality\n",
    "from cornac.metrics_explainer import (\n",
    "    Metric_Exp_FA as FA,\n",
    "    Metric_Exp_RA as RA,\n",
    ")\n",
    "\n",
    "\n",
    "rating = amazon_toy.load_feedback(fmt=\"UIRT\", reader=Reader(min_user_freq=50))\n",
    "sentiment_data = amazon_toy.load_sentiment(reader=Reader(min_user_freq=50))\n",
    "\n",
    "md = SentimentModality(data=sentiment_data)\n",
    "\n",
    "eval_method = StratifiedSplit(\n",
    "    data=rating,\n",
    "    group_by=\"user\",\n",
    "    chrono=True,\n",
    "    sentiment=md,\n",
    "    test_size=0.2,\n",
    "    exclude_unknowns=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# initialize recommenders and explainers\n",
    "efm = EFM(\n",
    "    max_iter=20,\n",
    "    num_explicit_factors=128,\n",
    "    num_latent_factors=128,\n",
    "    num_most_cared_aspects=100,\n",
    "    rating_scale=5.0,\n",
    "    alpha=0.9,\n",
    "    lambda_x=1,\n",
    "    lambda_y=1,\n",
    "    lambda_u=0.01,\n",
    "    lambda_h=0.01,\n",
    "    lambda_v=0.01,\n",
    "    trainable=True,\n",
    ")\n",
    "efm_exp = Exp_EFM(rec_model=efm, dataset=eval_method.train_set)\n",
    "\n",
    "mter = MTER(\n",
    "    max_iter=20,\n",
    "    n_user_factors=8,\n",
    "    n_item_factors=8,\n",
    "    n_aspect_factors=8,\n",
    "    n_opinion_factors=8,\n",
    "    n_bpr_samples=1000,\n",
    "    n_element_samples=50,\n",
    "    lambda_reg=0.1,\n",
    "    lambda_bpr=10,\n",
    "    lr=0.5,\n",
    ")\n",
    "mter_exp = Exp_MTER(rec_model=mter, dataset=eval_method.train_set)\n",
    "\n",
    "efm.fit(eval_method.train_set)\n",
    "params = {\n",
    "        \"U1\": efm.U1,\n",
    "        \"U2\": efm.U2,\n",
    "        \"H1\": efm.H1,\n",
    "        \"H2\": efm.H2,\n",
    "        \"V\": efm.V,\n",
    "}\n",
    "comparerobj = ComparERObj(\n",
    "    max_iter=20,\n",
    "    num_explicit_factors=128,\n",
    "    num_latent_factors=128,\n",
    "    num_most_cared_aspects=20,\n",
    "    rating_scale=5.0,\n",
    "    alpha=0.7,\n",
    "    lambda_x=1,\n",
    "    lambda_y=1,\n",
    "    lambda_u=0.01,\n",
    "    lambda_h=0.01,\n",
    "    lambda_v=0.01,\n",
    "    lambda_d=0.1,\n",
    "    min_user_freq=2,\n",
    "    trainable=True,\n",
    "    verbose=True,\n",
    "    init_params=params,\n",
    ")\n",
    "exp_comparerobj = Exp_ComparERObj(comparerobj, eval_method.train_set)\n",
    "\n",
    "mter.fit(eval_method.train_set)\n",
    "params = {\n",
    "    \"G1\": mter.G1,\n",
    "    \"G2\": mter.G2,\n",
    "    \"G3\": mter.G3,\n",
    "    \"U\": mter.U,\n",
    "    \"I\": mter.I,\n",
    "    \"A\": mter.A,\n",
    "    \"O\": mter.O,\n",
    "}\n",
    "\n",
    "comparersub = ComparERSub(\n",
    "    max_iter=20,\n",
    "    n_user_factors=8,\n",
    "    n_item_factors=8,\n",
    "    n_aspect_factors=8,\n",
    "    n_opinion_factors=8,\n",
    "    n_pair_samples=1000,\n",
    "    n_bpr_samples=1000,\n",
    "    n_element_samples=50,\n",
    "    lambda_reg=0.1,\n",
    "    lambda_bpr=10,\n",
    "    lambda_d=10,\n",
    "    lr=0.5,\n",
    "    min_common_freq=1,\n",
    "    min_user_freq=2,\n",
    "    min_pair_freq=1,\n",
    "    trainable=True,\n",
    "    verbose=True,\n",
    "    init_params=params,\n",
    ")\n",
    "exp_comparersub = Exp_ComparERSub(comparersub, eval_method.train_set)\n",
    "\n",
    "trirank = TriRank(\n",
    "    verbose=True,\n",
    "    seed=123,\n",
    ")\n",
    "exp_trirank = Exp_TriRank(rec_model=trirank, dataset=eval_method.train_set)\n",
    "# initialize metrics\n",
    "fa = FA()\n",
    "ra = RA()\n",
    "\n",
    "# initialize experiment\n",
    "models = [\n",
    "    [(efm, mter), (efm_exp, mter_exp)],\n",
    "    [(efm, comparerobj), (efm_exp, exp_comparerobj)],\n",
    "    [(mter, comparersub), (mter_exp, exp_comparersub)],\n",
    "    [(efm, trirank), (efm_exp, exp_trirank)]\n",
    "]\n",
    "metrics = [fa, ra]\n",
    "experiment = Experiment_Explainers(\n",
    "    eval_method=eval_method,\n",
    "    models=models,\n",
    "    metrics=metrics,\n",
    "    rec_k=10,\n",
    "    feature_k=10,\n",
    "    eval_train=True,\n",
    "    distribution=False,\n",
    ")\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 5**: Run FDIV with (NARRE, Exp_NARRE) with amazon_digital_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linan/miniconda3/envs/cornac/lib/python3.11/site-packages/tensorflow/python/debug/cli/debugger_cli_common.py:19: DeprecationWarning: module 'sre_constants' is deprecated\n",
      "  import sre_constants\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 126\n",
      "Number of items = 2829\n",
      "Number of ratings = 9809\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 4.2\n",
      "---\n",
      "Test data:\n",
      "Number of users = 126\n",
      "Number of items = 2829\n",
      "Number of ratings = 1129\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 126\n",
      "Number of items = 2829\n",
      "Number of ratings = 1121\n",
      "---\n",
      "Total users = 126\n",
      "Total items = 2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender NARRE...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OOV words: 4004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1ad4714c0f468ca97c2e838a1ae65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'NARRE:Exp_NARRE'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Recommender NARRE creates recommendations\n",
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer Exp_NARRE create explanation for all recommendations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning completed!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431614bd786c42b4adad678180e59a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/1260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_DIV starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Feature diversity: 0.3986967484915915\n",
      "INFO:cornac.experiment.experiment_explainers:experiment data: [[0.3986967484915915, 540.1019442081451, 2.2283430099487305]]\n",
      "INFO:cornac.experiment.experiment_explainers:Experiment result: \n",
      " recommender:explainer |     Metric_Exp_DIV |          Train(s) |        Evaluate(s)\n",
      "NARRE:Exp_NARRE       | 0.3986967484915915 | 540.1019442081451 | 2.2283430099487305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cornac.datasets import amazon_digital_music\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.data.reader import Reader\n",
    "from cornac.data import ReviewModality\n",
    "from cornac.data.text import BaseTokenizer\n",
    "from cornac.experiment import Experiment_Explainers\n",
    "from cornac.models import NARRE\n",
    "from cornac.explainer import Exp_NARRE\n",
    "from cornac.metrics_explainer import Metric_Exp_DIV\n",
    "\n",
    "\n",
    "feedback = amazon_digital_music.load_feedback(reader=Reader(min_user_freq=50))\n",
    "reviews = amazon_digital_music.load_review(reader=Reader(min_user_freq=50))\n",
    "\n",
    "\n",
    "review_modality = ReviewModality(\n",
    "    data=reviews,\n",
    "    tokenizer=BaseTokenizer(stop_words=\"english\"),\n",
    "    max_vocab=4000,\n",
    "    max_doc_freq=0.5,\n",
    ")\n",
    "\n",
    "ratio_split = RatioSplit(\n",
    "    data=feedback,\n",
    "    test_size=0.1,\n",
    "    val_size=0.1,\n",
    "    exclude_unknowns=True,\n",
    "    review_text=review_modality,\n",
    "    verbose=True,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "pretrained_word_embeddings = {}  # You can load pretrained word embedding here\n",
    "\n",
    "narre = NARRE(\n",
    "    embedding_size=100,\n",
    "    id_embedding_size=32,\n",
    "    n_factors=32,\n",
    "    attention_size=16,\n",
    "    kernel_sizes=[3],\n",
    "    n_filters=64,\n",
    "    dropout_rate=0.5,\n",
    "    max_text_length=50,\n",
    "    batch_size=64,\n",
    "    max_iter=10,\n",
    "    init_params={'pretrained_word_embeddings': pretrained_word_embeddings},\n",
    "    verbose=True,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "narre_exp = Exp_NARRE(rec_model=narre, dataset=ratio_split.train_set)\n",
    "\n",
    "div = Metric_Exp_DIV()\n",
    "\n",
    "experiment = Experiment_Explainers(\n",
    "    eval_method=ratio_split,\n",
    "    models=[(narre, narre_exp)],\n",
    "    metrics=[div],\n",
    "    rec_k=10,\n",
    "    feature_k=10,\n",
    "    eval_train=True,\n",
    "    distribution=False,\n",
    ")\n",
    "\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 6**: Run both experiment and experiment_explainers \n",
    "\n",
    "- Experiment: NDCG, AUC withe TriRank\n",
    "- Experiment_Explainers: Metric_Exp_DIV with (TriRank, Exp_TriRank) \n",
    "- Dataset: amazon_toy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 119\n",
      "Number of items = 4235\n",
      "Number of ratings = 7698\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 4.3\n",
      "---\n",
      "Test data:\n",
      "Number of users = 119\n",
      "Number of items = 4235\n",
      "Number of ratings = 836\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Total users = 119\n",
      "Total items = 4235\n",
      "\n",
      "[TriRank] Training started!\n",
      "Building matrices started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92112d55af04ee5b21bdea9d192b564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building matrices:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building symmetric normalized matrices R, X, Y\n",
      "Building matrices completed in 0 s\n",
      "\n",
      "[TriRank] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af45bb1bdef4d008170878c7111e922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Start training Recommender TriRank...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "        |    AUC | NDCG@50 | Train (s) | Test (s)\n",
      "------- + ------ + ------- + --------- + --------\n",
      "TriRank | 0.6445 |  0.0386 |    0.8550 |   6.4584\n",
      "\n",
      "Building matrices started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linan/miniconda3/envs/cornac/lib/python3.11/site-packages/cornac-2.0.0-py3.11-linux-x86_64.egg/cornac/models/recommender.py:307: UserWarning: Model is already fitted. Re-fitting will overwrite the previous model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59672037301f4ec3be78b61643629803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building matrices:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building symmetric normalized matrices R, X, Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:*****Start evaluating model-explainer: 'TriRank:Exp_TriRank'...\n",
      "INFO:cornac.experiment.experiment_explainers:Step 1/3: Recommender TriRank creates recommendations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building matrices completed in 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 2/3: Explainer Exp_TriRank create explanation for all recommendations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7f42cc2a4e41a39c52415e20f27d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing explanations:   0%|          | 0/1190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cornac.experiment.experiment_explainers:Step 3/3: Metric Metric_Exp_DIV starts evaluation...\n",
      "INFO:cornac.experiment.experiment_explainers:Result: Feature diversity: 0.24104642698256118\n",
      "INFO:cornac.experiment.experiment_explainers:experiment data: [[0.24104642698256118, 0.8859922885894775, 8.317068815231323]]\n",
      "INFO:cornac.experiment.experiment_explainers:Experiment result: \n",
      " recommender:explainer |      Metric_Exp_DIV |           Train(s) |       Evaluate(s)\n",
      "TriRank:Exp_TriRank   | 0.24104642698256118 | 0.8859922885894775 | 8.317068815231323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cornac.datasets import amazon_toy\n",
    "from cornac.data import SentimentModality\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.data.reader import Reader\n",
    "from cornac.experiment import Experiment_Explainers, Experiment\n",
    "from cornac.models import TriRank\n",
    "from cornac.explainer import Exp_TriRank\n",
    "from cornac.metrics_explainer import Metric_Exp_DIV\n",
    "from cornac.metrics import NDCG, AUC\n",
    "\n",
    "# Load rating and sentiment information\n",
    "rating = amazon_toy.load_feedback(reader=Reader(min_user_freq=50))\n",
    "sentiment = amazon_toy.load_sentiment(reader=Reader(min_user_freq=50))\n",
    "\n",
    "\n",
    "# Instantiate a SentimentModality, it makes it convenient to work with sentiment information\n",
    "md = SentimentModality(data=sentiment)\n",
    "\n",
    "\n",
    "# Define an evaluation method to split feedback into train and test sets\n",
    "eval_method = RatioSplit(\n",
    "    data=rating,\n",
    "    test_size=0.15,\n",
    "    exclude_unknowns=True,\n",
    "    verbose=True,\n",
    "    sentiment=md,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "# Instantiate the model\n",
    "trirank = TriRank(\n",
    "    verbose=True,\n",
    "    seed=123,\n",
    ")\n",
    "# Instantiate the explainer\n",
    "exp_trirank = Exp_TriRank(rec_model=trirank, dataset=eval_method.train_set)\n",
    "\n",
    "# Instantiate evaluation metrics\n",
    "ndcg_50 = NDCG(k=50)\n",
    "auc = AUC()\n",
    "\n",
    "# Run the experiment for the TriRank model\n",
    "Experiment(\n",
    "    eval_method=eval_method, models=[trirank], metrics=[ndcg_50, auc]\n",
    ").run()\n",
    "\n",
    "# initialize metrics for explainers\n",
    "div = Metric_Exp_DIV()\n",
    "\n",
    "# Run the experiment for the TriRank model with the explainer\n",
    "Experiment_Explainers(\n",
    "    eval_method=eval_method,\n",
    "    models=[(trirank, exp_trirank)],\n",
    "    metrics=[div],\n",
    "    rec_k=10,\n",
    "    feature_k=10,\n",
    "    eval_train=True,\n",
    "    distribution=False,\n",
    ").run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ebbe97ee2486d44b314e7fb9a74c6e9ddf9ecd1c9e636490160d240e80178cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
