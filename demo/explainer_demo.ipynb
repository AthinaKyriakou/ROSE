{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of one explainer\n",
    "\n",
    "Take EFM and Exp_EFM as an example, and use dataset amazon_toy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.datasets import amazon_toy\n",
    "from cornac.data.reader import Reader\n",
    "from cornac.eval_methods import StratifiedSplit\n",
    "from cornac.data.sentiment import SentimentModality\n",
    "from cornac.models import EFM\n",
    "from cornac.explainer import Exp_EFM\n",
    "\n",
    "# Load the Amazon toy dataset\n",
    "rating = amazon_toy.load_feedback(fmt=\"UIRT\", reader=Reader(min_user_freq=20))\n",
    "sentiment_data = amazon_toy.load_sentiment(reader=Reader(min_user_freq=20))\n",
    "md = SentimentModality(data=sentiment_data)\n",
    "\n",
    "eval_method = StratifiedSplit(\n",
    "    data=rating,\n",
    "    group_by=\"user\",\n",
    "    chrono=True,\n",
    "    sentiment=md,\n",
    "    test_size=0.2,\n",
    "    exclude_unknowns=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Instantiate the EFM model\n",
    "efm = EFM(\n",
    "    max_iter=20,\n",
    "    num_explicit_factors=128,\n",
    "    num_latent_factors=128,\n",
    "    num_most_cared_aspects=100,\n",
    "    rating_scale=5.0,\n",
    "    alpha=0.9,\n",
    "    lambda_x=1,\n",
    "    lambda_y=1,\n",
    "    lambda_u=0.01,\n",
    "    lambda_h=0.01,\n",
    "    lambda_v=0.01,\n",
    "    trainable=True,\n",
    ")\n",
    "efm.fit(eval_method.train_set)\n",
    "\n",
    "\n",
    "# Instantiate the explainer\n",
    "explainer = Exp_EFM(rec_model=efm, dataset=eval_method.train_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need some recommendations\n",
    "some_users = eval_method.test_set.user_ids[:3]\n",
    "recomendations = efm.recommend_to_multiple_users(some_users, k=5)\n",
    "print(recomendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.explain_recommendations(recomendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain one user-item pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_user = eval_method.train_set.user_ids[0]\n",
    "one_item = eval_method.train_set.item_ids[0]\n",
    "explanation = explainer.explain_one_recommendation_to_user(one_user, one_item, feature_k=8)\n",
    "print(f\"For User {one_user} and Item {one_item}:\")\n",
    "print(\"Explanation:\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain one user-item with ref-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_user = eval_method.train_set.user_ids[0]\n",
    "one_item = eval_method.train_set.item_ids[0]\n",
    "ref_item = eval_method.train_set.item_ids[10]\n",
    "explanation = explainer.explain_one_with_ref(user_id=one_user, item_id=one_item, ref_item_id=ref_item)\n",
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanation for user-item\n",
    "print(explanation['explanation'])\n",
    "# and explanation for user-ref_item\n",
    "print(explanation['ref_explanation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plot for Exp_EFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = eval_method.test_set.user_ids\n",
    "recommendations = efm.recommend_to_multiple_users(users, k=10)\n",
    "explanations = explainer.explain_recommendations(recommendations, feature_k=8)\n",
    "explanations_df = explanations.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.visualization import Visualization\n",
    "my_plots = Visualization()\n",
    "\n",
    "# Create a plot for a specific user and item\n",
    "one_user = eval_method.train_set.user_ids[15]\n",
    "one_item = eval_method.train_set.item_ids[0]\n",
    "ind_df = my_plots.create_individual_feature_importance_plot(\n",
    "    explanations,\n",
    "    user_id=one_user,\n",
    "    item_id=one_item,\n",
    "    type=\"bar\",\n",
    "    top_k=6,\n",
    "    save_plot=False,\n",
    ")\n",
    "\n",
    "filtered_df = my_plots.create_aggregate_feature_importance_plot(\n",
    "    explanations, type=\"bar\", top_k=8, save_plot=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('clean_venv_1': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "b57536c29832a493ae4ab70cab961bc0266617103a127cbea54d44f7949475d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
