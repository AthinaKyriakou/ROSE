import numpy as np
import pandas as pd
import multiprocessing
import tqdm
import copy

from ..metrics import Metrics

class PGF(Metrics):
    """
    Prediction Gap Fidelity
    Parameters
    ----------
    rec_k: int, optional, default: 10
        Number of recommendations for each user.
    feature_k: int, optional, default: 10
        Number of elements in one explanation.
    num_threads: int, optional, default: 0
        Number of parallel threads for training. If num_threads=0, all CPU cores will be utilized.
        If seed is not None, num_threads=1 to remove randomness from parallelization.
    phi: float, optional, default: 0.1
        The noise level.
    name: str, optional, default: 'PGF'
    
    References
    ----------
    Jessica Dai, Sohini Upadhyay, Ulrich Aivodji, Stephen H. Bach, and Himabindu Lakkaraju. 2022. \
    Fairness via Explanation Quality: Evaluating Disparities in the Quality of Post hoc Explanations. \  
    In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society, 203-214. DOI:https://doi.org/10.1145/3514094.3534159
    """
    def __init__(self,
            rec_k=10,
            feature_k=10,
            num_threads=0,
            phi=0.1,
            name='PGF'):

        super().__init__(name=name, rec_k=rec_k, feature_k=feature_k)
        if num_threads > 0 and num_threads < multiprocessing.cpu_count():
            self.num_threads = num_threads
        else:
            self.num_threads = multiprocessing.cpu_count()
            
        self.phi = phi

    def compute(self, recommender, explainer, explanations, distribution=False):
        """
        The main function to compute PGF
        Parameters
        ----------
        recommender: object
            Trained recommender model.
        explainer: object
            The explainer model.
        explanations: array-like
            The explanations generated by the explainer model for all recommendations.
        """
        
        if not hasattr(recommender, 'train_set'):
            # print('Please train model first!')
            # return
            raise AttributeError("The recommender is not trained yet.")
        if explainer.name not in ['EMF', 'PHI4MF', 'ALS']:
            raise NotImplementedError("The explainer does not support this recommender.")

        self.recommender = recommender
        self.explainer = explainer
        self.dataset = self.recommender.train_set
        self.explanations = explanations
        self.gaps = np.zeros(self.dataset.num_users)
        
        self.model_copy = copy.deepcopy(self.recommender)
        self.model_copy.train_set = copy.deepcopy(self.recommender.train_set)
        
        self.idx2iid = {v:k for k,v in self.dataset.iid_map.items()}
        self.idx2uid = {v:k for k,v in self.dataset.uid_map.items()}
        
        pgf = self._compute_PGF()
        return pgf, self.gaps


    def _get_top_elements(self, user_idx):
        """
        Get the top elements in explanations for one user
        Parameters
        ----------
        user_idx: int
            The index of the user(not id).
        """
        if self.explainer.name == 'EMF':
            return self.recommender.sim_users[user_idx][:self.feature_k]
        elif self.explainer.name == 'PHI4MF':
            user_id = self.idx2uid[user_idx]
            explanations = self.explanations[self.explanations[:, 0] == user_id][:, 2]
            # get the item id before "=>"
            item_ids = []
            type_iid_map_key = type(list(self.dataset.iid_map.keys())[0])        
            for explanation in explanations:
                for item in explanation:
                    if len(item) == 0:
                        continue
                    item_id = item.split('=>')[0]
                    # make item_id is the same type as in dataset.iid_map
                    if isinstance(item_id, type_iid_map_key):
                        item_ids.append(item_id)
                    else:
                        try:
                            item_id = type_iid_map_key(item_id)
                            item_ids.append(item_id)
                        except ValueError:
                            continue
            item_idxs = [self.dataset.iid_map[item_id] for item_id in item_ids]
            return item_idxs
        elif self.explainer.name == 'ALS':
            user_id = self.idx2uid[user_idx]
            explanations = self.explanations[self.explanations[:, 0] == user_id][:, 2]
            # explanations is a dict with item_id as key
            item_ids = []
            for explanation in explanations:
                item_ids.extend(list(explanation))
            item_idxs = [self.dataset.iid_map[item_id] for item_id in item_ids]
            return item_idxs
                

    def _compute_PGF(self):
        """
        Compute PGF
        """
        self.gaps = np.zeros(self.dataset.num_users)
        if self.explainer.name == 'EMF':
            sum_pgf = 0
            for user_idx in tqdm.tqdm(range(self.dataset.num_users)):
                top_elements = self._get_top_elements(user_idx)
                # add noise to lanten factors
                for u in range(self.dataset.num_users):
                    if u not in top_elements:
                        self.model_copy.u_factors[u] += np.random.normal(0, self.phi, self.model_copy.u_factors.shape[1])
                old_scores = self.recommender.score(user_idx)
                new_scores = self.model_copy.score(user_idx)
                diff = self._compute_difference(old_scores, new_scores)
                sum_pgf += diff
                self.gaps[user_idx] = diff
            return sum_pgf / self.dataset.num_users 
            
        elif self.explainer.name in ['PHI4MF', 'ALS']:
            sum_pgf = 0
            for user_idx in tqdm.tqdm(range(self.dataset.num_users)):
                top_elements = self._get_top_elements(user_idx)
                for i in range(self.dataset.num_items):
                    if i not in top_elements:
                        self.model_copy.i_factors[i] += np.random.normal(0, self.phi, self.model_copy.i_factors.shape[1])
                old_scores = self.recommender.score(user_idx)
                new_scores = self.model_copy.score(user_idx)
                diff = self._compute_difference(old_scores, new_scores)
                sum_pgf += diff
                self.gaps[user_idx] = diff
            return sum_pgf / self.dataset.num_users 
        
    def _compute_difference(self, old_scores, new_scores):
        """
        Compute the difference between old scores and new scores
        """
        # old_scores = np.exp(old_scores) / np.sum(np.exp(old_scores))
        # because the possibility is too small, change to max-min normalization
        old_scores = (old_scores - np.min(old_scores)) / (np.max(old_scores) - np.min(old_scores))
        # if there is invalid item, return 0
        if np.isnan(old_scores).any():
            return 0
        # new_scores = np.exp(new_scores) / np.sum(np.exp(new_scores))
        new_scores = (new_scores - np.min(new_scores)) / (np.max(new_scores) - np.min(new_scores))
        if np.isnan(new_scores).any():
            return 0
        # return np.sum(np.abs(old_scores - new_scores))
        return np.mean(np.abs(old_scores - new_scores))
