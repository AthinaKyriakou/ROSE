{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cornac\n",
    "from cornac.models import EFM, MTER, NMF, BPR\n",
    "from cornac.explainer import EFMExplainer, MTERExplainer, Mod_EFMExplainer\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.data import Reader, SentimentModality\n",
    "VERBOSE = False\n",
    "SEED = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_fpath = '../tests/dataset/goodreads_sentiment.txt'\n",
    "sentiment = Reader().read(sentiment_fpath, fmt='UITup', sep=',', tup_sep=':')\n",
    "# Load rating and sentiment information\n",
    "rating_fpath = '../tests/dataset/goodreads_rating.txt'\n",
    "rating = Reader(min_item_freq=20).read(rating_fpath, fmt='UIR', sep=',')\n",
    "sentiment_modality = SentimentModality(data=sentiment)\n",
    "rs = RatioSplit(\n",
    "            data=rating,\n",
    "            test_size=0.2,\n",
    "            exclude_unknowns=True,\n",
    "            sentiment=sentiment_modality,\n",
    "            verbose=VERBOSE,\n",
    "            seed=SEED,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize models and get recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/z6_kxvwj695fk45rl_9jd3k40000gn/T/ipykernel_1679/2931175316.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  efm.fit(rs.train_set)\n",
      "/var/folders/yd/z6_kxvwj695fk45rl_9jd3k40000gn/T/ipykernel_1679/2931175316.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  efm.fit(rs.train_set)\n"
     ]
    }
   ],
   "source": [
    "from cornac.datasets.goodreads import prepare_data\n",
    "rs = prepare_data(data_name=\"goodreads\")\n",
    "efm = EFM()\n",
    "efm.fit(rs.train_set)\n",
    "efm_explainer = EFMExplainer(efm, efm.train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "...\n",
      "     |   RMSE |    AUC | NDCG@50 | Train (s) | Test (s)\n",
      "---- + ------ + ------ + ------- + --------- + --------\n",
      "EFM  | 0.9013 | 0.6208 |  0.0634 |    2.4847 |   6.4599\n",
      "MTER | 1.2058 | 0.7831 |  0.1389 |   22.8753 |   0.6254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "efm = EFM(\n",
    "    num_explicit_factors = 40,\n",
    "    num_latent_factors = 60,\n",
    "    num_most_cared_aspects = 15,\n",
    "    rating_scale = 5.0,\n",
    "    alpha = 0.85,\n",
    "    lambda_x = 1,\n",
    "    lambda_y = 1,\n",
    "    lambda_u = 0.01,\n",
    "    lambda_h = 0.01,\n",
    "    lambda_v = 0.01,\n",
    "    max_iter = 100,\n",
    "    verbose = VERBOSE,\n",
    "    seed = SEED,\n",
    ")\n",
    "\n",
    "mter = MTER(\n",
    "    n_user_factors = 10,\n",
    "    n_item_factors = 10,\n",
    "    n_aspect_factors = 10,\n",
    "    n_opinion_factors = 10,\n",
    "    n_bpr_samples = 1000,\n",
    "    n_element_samples = 50,\n",
    "    lambda_reg = 0.1,\n",
    "    lambda_bpr = 10,\n",
    "    max_iter = 3000,\n",
    "    lr = 0.5,\n",
    "    verbose = VERBOSE,\n",
    "    seed = SEED,\n",
    ")\n",
    "\n",
    "#nmf = NMF(k=100, max_iter=100, verbose=VERBOSE, seed=SEED)\n",
    "#bpr = BPR(k=10, verbose = VERBOSE, seed = SEED)\n",
    "\n",
    "eval_metrics = [\n",
    "    cornac.metrics.RMSE(),\n",
    "    cornac.metrics.NDCG(k=50),\n",
    "    cornac.metrics.AUC()\n",
    "]\n",
    "\n",
    "cornac.Experiment(\n",
    "    eval_method = rs, models=[efm, mter], metrics = eval_metrics\n",
    ").run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFMExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx_list = [1, 2, 3, 4, 5]\n",
    "# get recommendation list from EFM\n",
    "recom_list_efm = [[idx, efm.rank(idx)[0][0]] for idx in user_idx_list]\n",
    "# transform to dataframe\n",
    "recom_df_efm = pd.DataFrame(recom_list_efm, columns=['user_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend user 1 item 1, because it performs well on the aspect: kiddies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing explanations: 100%|██████████| 5/5 [00:00<00:00, 226.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain more recommendations\n",
      "user_id item_id   aspect  aspect_score\n",
      "      1       6  kiddies      6.367883\n",
      "      2     102    kings      5.694288\n",
      "      3       1 claptrap      6.422020\n",
      "      4       6       ed      6.387510\n",
      "      5      88  workout      5.851394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize explainer\n",
    "efm_exp = EFMExplainer(efm, efm.train_set)\n",
    "# explain 1 recommendation\n",
    "explanation_1 = efm_exp.explain_one_recommendation_to_user(user_id=1, item_id=1, index=True)\n",
    "print(f\"Recommend user {explanation_1['user_id'][0]} item {explanation_1['item_id'][0]}, because it performs well on the aspect: {explanation_1['aspect'][0]}\")\n",
    "\n",
    "# explain more recommendations\n",
    "explanations = efm_exp.explain_recommendations(recom_df_efm)\n",
    "explanations = pd.DataFrame(explanations, columns=['user_id', 'item_id', 'aspect', 'aspect_score'])\n",
    "print(\"Explain more recommendations\")\n",
    "print(explanations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend user 000d8d73b2676e0c0858a485fe21d56c item 10048521, because it performs well on the aspect: claptrap\n"
     ]
    }
   ],
   "source": [
    "# when the input is real id not index, set index=False\n",
    "explanation_1 = efm_exp.explain_one_recommendation_to_user(user_id='000d8d73b2676e0c0858a485fe21d56c', item_id='10048521', index=False)\n",
    "print(f\"Recommend user {explanation_1['user_id'][0]} item {explanation_1['item_id'][0]}, because it performs well on the aspect: {explanation_1['aspect'][0]}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified_EFMExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend item 1 to user 3 , because the score of aspect: fools is 3.217013120651245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing explanations: 100%|██████████| 5/5 [00:02<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain more recommendations\n",
      "user_id item_id recommend    aspect  aspect_score max_aspect_name  max_aspect_score\n",
      "      1       6     False   stomach      2.888605         twister          4.728925\n",
      "      2     102     False writingis      2.377862          trains          4.058887\n",
      "      3       1      True     fools      3.217013     furnishings          4.445765\n",
      "      4       6     False    bother      1.278869         twister          4.728925\n",
      "      5      88     False  prospect      2.501148      accusation          4.102617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize explainer\n",
    "mod_efm_exp = Mod_EFMExplainer(efm, efm.train_set)\n",
    "# explain 1 recommendation\n",
    "explanation_1 = mod_efm_exp.explain_one_recommendation_to_user(user_id=3, item_id=1, index=True)\n",
    "recommend_or_not = \"Recommend\" if explanation_1['recommend'][0] == True else \"Not recommend\"\n",
    "print(f\"{recommend_or_not} item {explanation_1['item_id'][0]} to user {explanation_1['user_id'][0]} , because the score of aspect: {explanation_1['aspect'][0]} is {explanation_1['aspect_score'][0]}\")\n",
    "\n",
    "# explain more recommendations\n",
    "explanations = mod_efm_exp.explain_recommendations(recom_df_efm)\n",
    "explanations = pd.DataFrame(explanations, columns=['user_id', 'item_id', 'recommend', 'aspect', 'aspect_score', 'max_aspect_name','max_aspect_score'])\n",
    "print(\"Explain more recommendations\")\n",
    "print(explanations.to_string(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTERExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recommendation list from MTER\n",
    "recom_list_mter = [[idx, mter.rank(idx)[0][0]] for idx in user_idx_list]\n",
    "recom_df_mter = pd.DataFrame(recom_list_mter, columns=['user_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend user 1 item 1, because people's opinion on the aspect: circlejerk is odd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing explanations: 100%|██████████| 5/5 [00:00<00:00, 367.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain more recommendations\n",
      "user_id item_id     aspect   opinion\n",
      "      1       1 circlejerk       odd\n",
      "      2       2    overuse       ill\n",
      "      3     100  converges   council\n",
      "      4       1        pan  poignant\n",
      "      5       5     nitwit contrived\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize explainer\n",
    "mter_exp = MTERExplainer(mter, mter.train_set)\n",
    "# explain 1 recommendation\n",
    "explanation_1 = mter_exp.explain_one_recommendation_to_user(user_id=1, item_id=1, index=True)\n",
    "print(f\"Recommend user {explanation_1['user_id'][0]} item {explanation_1['item_id'][0]}, because people's opinion on the aspect: {explanation_1['aspect'][0]} is {explanation_1['opinion'][0]}\")\n",
    "\n",
    "# explain more recommendations\n",
    "explanations = mter_exp.explain_recommendations(recom_df_mter)\n",
    "explanations = pd.DataFrame(explanations, columns=['user_id', 'item_id', 'aspect', 'opinion'])\n",
    "print(\"Explain more recommendations\")\n",
    "print(explanations.to_string(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### question of recommend()\n",
    "note: which position is better to place the sentiment_generation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EFM(EFM):\n",
    "    def __init__(self, name=\"EFM\",\n",
    "                 num_explicit_factors=40, num_latent_factors=60, num_most_cared_aspects=15,\n",
    "                 rating_scale=5.0, alpha=0.85,\n",
    "                 lambda_x=1, lambda_y=1, lambda_u=0.01, lambda_h=0.01, lambda_v=0.01,\n",
    "                 use_item_aspect_popularity=True, max_iter=100,\n",
    "                 num_threads=0, trainable=True, verbose=False, init_params=None, seed=None):\n",
    "        super().__init__(self, )\n",
    "        \n",
    "    def recommend_to_one_user(self, user_idx):\n",
    "        \"\"\"\n",
    "        Provide top-N recommendations for a list of users\n",
    "        user_idx: list of user indices\n",
    "        n: number of items to recommend\n",
    "        \n",
    "        return: a list [user_id, item_id, score]\n",
    "        \"\"\"\n",
    "        item_rank, item_scores = self.rank(user_idx)\n",
    "        return [user_idx, item_rank[0], item_scores[0]]\n",
    "    \n",
    "    def recommend_to_all_users(self, user_list=None):\n",
    "        \"\"\"\n",
    "        Provide top-N recommendations for all users\n",
    "        n: number of items to recommend\n",
    "        \n",
    "        return: a list of [[user_id, item_id, score], ...]\n",
    "        \"\"\"\n",
    "        self.user_list = user_list\n",
    "        if self.user_list is None:\n",
    "            self.user_list = [idx for idx in range(self.train_set.num_users)]\n",
    "        else:\n",
    "            self.user_list = [idx for idx in self.user_list if idx in range(self.train_set.num_users)]\n",
    "        recommendations = []\n",
    "        with tqdm(total=len(self.user_list), desc=\"Computing recommendations: \") as pbar:\n",
    "            for user_idx in self.user_list:\n",
    "                # append result to recommendations\n",
    "                recommendations.append(self.recommend_to_one_user(user_idx))\n",
    "                self.recommend_to_one_user(user_idx)\n",
    "                pbar.update(1)\n",
    "        # transform recommendations to dataframe\n",
    "        recommendations = pd.DataFrame(recommendations, columns=['user_id', 'item_id', 'score'])\n",
    "        # return 'user_id', 'item_id'\n",
    "        return recommendations[['user_id', 'item_id']]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing recommendations: 100%|██████████| 1/1 [00:00<00:00, 421.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id\n",
       "0        1       50"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_idx_list = [1, 2, 3, 4, 5]\n",
    "efm = EFM().fit(rs.train_set)\n",
    "\n",
    "#recom_list_efm = [[idx, efm.rank(idx)[0][0]] for idx in user_idx_list]\n",
    "#recom_df_efm = pd.DataFrame(recom_list_efm, columns=['user_id', 'item_id'])\n",
    "recom_df_efm = efm.recommend_to_all_users(user_list=[user_idx_list[0]])\n",
    "\n",
    "recom_df_efm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
