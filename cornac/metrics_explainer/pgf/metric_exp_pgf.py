import numpy as np
import pandas as pd
import multiprocessing
import tqdm
import copy

from ..metric_exp import Metric_Exp


class Metric_Exp_PGF(Metric_Exp):
    """Prediction Gap Fidelity

    Parameters
    ----------
    rec_k: int, optional, default: 10
        Number of recommendations for each user.
    feature_k: int, optional, default: 10
        Number of elements in one explanation.
    num_threads: int, optional, default: 0
        Number of parallel threads for training. If num_threads=0, all CPU cores will be utilized.
        If seed is not None, num_threads=1 to remove randomness from parallelization.
    phi: float, optional, default: 0.1
        The noise level.
    name: str, optional, default: 'Metric_Exp_PGF'

    References
    ----------
    [1] Jessica Dai, Sohini Upadhyay, Ulrich Aivodji, Stephen H. Bach, and Himabindu Lakkaraju. 2022. Fairness via Explanation Quality: Evaluating Disparities in the Quality of Post hoc Explanations. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society, 203-214. DOI:https://doi.org/10.1145/3514094.3534159
    """

    def __init__(
        self, rec_k=10, feature_k=10, num_threads=0, phi=0.1, name="Metric_Exp_PGF"
    ):

        super().__init__(name=name, rec_k=rec_k, feature_k=feature_k)
        if num_threads > 0 and num_threads < multiprocessing.cpu_count():
            self.num_threads = num_threads
        else:
            self.num_threads = multiprocessing.cpu_count()

        self.phi = phi

    def compute(self, recommender, explainer, explanations, distribution=False):
        """The main function to compute PGF

        Parameters
        ----------
        recommender: object
            Trained recommender model.
        explainer: object
            The explainer model.
        explanations: array-like
            The explanations generated by the explainer model for all recommendations.

        Returns
        -------
        pgf: float
            The PGF value.
        gaps: array-like
            The gaps for each user.
        """

        if not hasattr(recommender, "train_set"):
            # print('Please train model first!')
            # return
            raise AttributeError("The recommender is not trained yet.")

        self.recommender = recommender
        self.explainer = explainer
        self.dataset = self.recommender.train_set
        self.explanations = explanations
        self.gaps = np.zeros(self.dataset.num_users)

        self.model_copy = copy.deepcopy(self.recommender)
        self.model_copy.train_set = copy.deepcopy(self.recommender.train_set)

        self.idx2iid = {v: k for k, v in self.dataset.iid_map.items()}
        self.idx2uid = {v: k for k, v in self.dataset.uid_map.items()}

        pgf = self._compute_PGF()
        return pgf, self.gaps

    def _get_top_elements(self, user_idx):
        """
        Get the top elements in explanations for one user
        Parameters
        ----------
        user_idx: int
            The index of the user(not id).
        """
        if self.explainer.name == "Exp_SU4EMF":
            return self.recommender.sim_users[user_idx][: self.feature_k]
        elif self.explainer.name == "Exp_PHI4MF":
            user_id = self.idx2uid[user_idx]
            explanations = self.explanations[self.explanations[:, 0] == user_id][:, 2]
            # get the item id before "=>"
            item_ids = []
            type_iid_map_key = type(list(self.dataset.iid_map.keys())[0])
            for explanation in explanations:
                for item in explanation:
                    if len(item) == 0:
                        continue
                    # s = item.split("=>")[0]
                    s = item
                    s = s.replace("[", "")
                    s = s.replace("]", "")
                    s = s.replace("'", "")
                    antecedents = s.split(", ")
                    for item_id in antecedents:
                        # make item_id is the same type as in dataset.iid_map
                        if isinstance(item_id, type_iid_map_key):
                            item_ids.append(item_id)
                        else:
                            try:
                                item_id = type_iid_map_key(item_id)
                                item_ids.append(item_id)
                            except ValueError:
                                continue
            item_idxs = [self.dataset.iid_map[item_id] for item_id in item_ids]
            return item_idxs
        elif self.explainer.name == "Exp_ALS":
            user_id = self.idx2uid[user_idx]
            explanations = self.explanations[self.explanations[:, 0] == user_id][:, 2]
            # explanations is a dict with item_id as key
            item_ids = []
            for explanation in explanations:
                item_ids.extend(list(explanation))
            item_idxs = [self.dataset.iid_map[item_id] for item_id in item_ids]
            return item_idxs

    def _compute_PGF(self):
        """
        Compute PGF
        """
        self.gaps = np.zeros(self.dataset.num_users)
        if self.explainer.name == "Exp_SU4EMF":
            sum_pgf = 0
            for user_idx in tqdm.tqdm(range(self.dataset.num_users)):
                top_elements = self._get_top_elements(user_idx)
                # add noise to lanten factors
                for u in range(self.dataset.num_users):
                    if u not in top_elements:
                        self.model_copy.u_factors[u] += np.random.normal(
                            0, self.phi, self.model_copy.u_factors.shape[1]
                        )
                old_scores = self.recommender.score(user_idx)
                new_scores = self.model_copy.score(user_idx)
                diff = self._compute_difference(old_scores, new_scores)
                sum_pgf += diff
                self.gaps[user_idx] = diff
            return sum_pgf / self.dataset.num_users

        elif self.explainer.name in ["Exp_PHI4MF", "Exp_ALS"]:
            sum_pgf = 0
            for user_idx in tqdm.tqdm(range(self.dataset.num_users)):
                top_elements = self._get_top_elements(user_idx)
                for i in range(self.dataset.num_items):
                    if i not in top_elements:
                        self.model_copy.i_factors[i] += np.random.normal(
                            0, self.phi, self.model_copy.i_factors.shape[1]
                        )
                old_scores = self.recommender.score(user_idx)
                new_scores = self.model_copy.score(user_idx)
                diff = self._compute_difference(old_scores, new_scores)
                sum_pgf += diff
                self.gaps[user_idx] = diff
            return sum_pgf / self.dataset.num_users

    def _compute_difference(self, old_scores, new_scores):
        """
        Compute the difference between old scores and new scores
        """
        # old_scores = np.exp(old_scores) / np.sum(np.exp(old_scores))
        # because the possibility is too small, change to max-min normalization
        old_scores = (old_scores - np.min(old_scores)) / (
            np.max(old_scores) - np.min(old_scores)
        )
        # if there is invalid item, return 0
        if np.isnan(old_scores).any():
            return 0
        # new_scores = np.exp(new_scores) / np.sum(np.exp(new_scores))
        new_scores = (new_scores - np.min(new_scores)) / (
            np.max(new_scores) - np.min(new_scores)
        )
        if np.isnan(new_scores).any():
            return 0
        # return np.sum(np.abs(old_scores - new_scores))
        return np.mean(np.abs(old_scores - new_scores))
